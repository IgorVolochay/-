{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5. , 3.4, 1.5, 0.2],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [4.8, 3.4, 1.6, 0.2],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [5.1, 3.5, 1.4, 0.3],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [5. , 3. , 1.6, 0.2],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [5.2, 3.4, 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.2, 4.1, 1.5, 0.1],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.6, 1.4, 0.1],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [5. , 3.5, 1.3, 0.3],\n",
      "       [4.5, 2.3, 1.3, 0.3],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [5.1, 3.8, 1.6, 0.2],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [5. , 3.3, 1.4, 0.2],\n",
      "       [7. , 3.2, 4.7, 1.4],\n",
      "       [6.4, 3.2, 4.5, 1.5],\n",
      "       [6.9, 3.1, 4.9, 1.5],\n",
      "       [5.5, 2.3, 4. , 1.3],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [6.1, 2.9, 4.7, 1.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.7, 3.1, 4.4, 1.4],\n",
      "       [5.6, 3. , 4.5, 1.5],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.9, 3.2, 4.8, 1.8],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.7, 3. , 5. , 1.7],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [5.5, 2.4, 3.8, 1.1],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [5.4, 3. , 4.5, 1.5],\n",
      "       [6. , 3.4, 4.5, 1.6],\n",
      "       [6.7, 3.1, 4.7, 1.5],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [5.5, 2.5, 4. , 1.3],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.6, 2.7, 4.2, 1.3],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [6.2, 2.9, 4.3, 1.3],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [4.9, 2.5, 4.5, 1.7],\n",
      "       [7.3, 2.9, 6.3, 1.8],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [7.2, 3.6, 6.1, 2.5],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [6.8, 3. , 5.5, 2.1],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.2, 5. , 1.5],\n",
      "       [6.9, 3.2, 5.7, 2.3],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [7.7, 2.8, 6.7, 2. ],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [6.7, 3.3, 5.7, 2.1],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [6.2, 2.8, 4.8, 1.8],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.2, 3. , 5.8, 1.6],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [6.3, 2.8, 5.1, 1.5],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [6.4, 3.1, 5.5, 1.8],\n",
      "       [6. , 3. , 4.8, 1.8],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [6.7, 3.1, 5.6, 2.4],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'C:\\\\Users\\\\79787\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37-32\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка основной инфы для ирисов\n",
    "iris = datasets.load_iris()\n",
    "print(iris)\n",
    "# Создаём двумерную таблицу, и вставляем инфу о длине\\ширине чашелистика, и о длине\\ширине лепестка\n",
    "iris_frame = pd.DataFrame(iris.data)\n",
    "# Подписываем индексы\n",
    "iris_frame.columns = iris.feature_names\n",
    "\n",
    "# Добавляем столбец с целевой переменной (0 - setosa, 1 - versicolor, 2 - virginica)\n",
    "iris_frame['target'] = iris.target\n",
    "# Для наглядности добавляем столбец с сортами\n",
    "iris_frame['name'] = iris_frame.target.apply(lambda x: iris.target_names[x])\n",
    "\n",
    "#iris_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.16054136 -1.05644028  0.52971442 -0.84238071]\n",
      " [ 2.26394945  1.49426941  0.75195188  1.64402921]\n",
      " [-0.28458654 -1.14568917  0.54316564 -0.36342075]\n",
      " [ 0.0921968  -0.54177657  0.26726524 -0.47214936]]\n",
      "\n",
      "[[ 0.16314118  0.04374249  1.41243426 -2.8135857 ]\n",
      " [-0.68052871  1.03439456  0.47834903  0.55243532]\n",
      " [-0.10306842 -0.57055062  0.70162162 -0.30746884]\n",
      " [ 0.41524132 -0.02560832 -0.75104105  1.96995806]]\n",
      "\n",
      "[[-0.67950895 -0.71710945  1.51589747  0.17714679]\n",
      " [ 1.64163432 -0.3902997   0.50589237  0.97970217]\n",
      " [-0.2860645  -0.04872755 -2.15266782  0.74217851]\n",
      " [ 0.51176507  0.12228455 -0.77670581 -0.61917399]]\n",
      "\n",
      "[[ 0.16106065]\n",
      " [-0.63282358]\n",
      " [ 0.5305212 ]\n",
      " [-1.04640627]]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.00003\n",
    "\n",
    "weight_1_2 = np.random.randn(4, 4)\n",
    "weight_2_3 = np.random.randn(4, 4)\n",
    "weight_3_4 = np.random.randn(4, 4)\n",
    "weight_4_5 = np.random.randn(4, 1)\n",
    "\n",
    "print(weight_1_2, weight_2_3, weight_3_4, weight_4_5, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(250):\n",
    "    for i in range(len(iris_frame[\"sepal length (cm)\"])):\n",
    "        inp = [iris_frame[\"sepal length (cm)\"][i], iris_frame[\"sepal width (cm)\"][i], iris_frame[\"petal length (cm)\"][i], iris_frame[\"petal width (cm)\"][i]]\n",
    "        goal_pred = iris_frame[\"target\"][i]\n",
    "        \n",
    "        layer_2 = np.dot(inp, weight_1_2)\n",
    "        layer_3 = np.dot(layer_2, weight_2_3)\n",
    "        layer_4 = np.dot(layer_3, weight_3_4)\n",
    "        pred = np.sum(np.dot(layer_4, weight_4_5))\n",
    "        if iteration % 100 == 0:\n",
    "            if pred <= 0.5:\n",
    "                print(\"It is a - setosa\", goal_pred, pred)\n",
    "            elif pred > 0.7 and pred <= 1.5:\n",
    "                print(\"It is a - versicolor\", goal_pred, pred)\n",
    "            elif pred > 1.7 and pred <= 2.5:\n",
    "                print(\"It is a - virginica\", goal_pred, pred)\n",
    "            else:\n",
    "                print(\"I dont know\", goal_pred, pred)\n",
    "\n",
    "        error = (pred - goal_pred) ** 2\n",
    "        layer_5_delta = pred - goal_pred\n",
    "        layer_4_delta = np.sum(np.dot(layer_5_delta, weight_4_5))\n",
    "        layer_3_delta = np.sum(np.dot(layer_4_delta, weight_3_4))\n",
    "        layer_2_delta = np.sum(np.dot(layer_3_delta, weight_2_3))\n",
    "\n",
    "        weight_delta_1_2 = np.zeros(weight_1_2.shape)\n",
    "        weight_delta_2_3 = np.zeros(weight_2_3.shape)\n",
    "        weight_delta_3_4 = np.zeros(weight_3_4.shape)\n",
    "        weight_delta_4_5 = np.zeros(weight_4_5.shape)\n",
    "\n",
    "        for k in range(len(weight_delta_1_2)):\n",
    "            for j in range(len(weight_delta_1_2[k])):\n",
    "                weight_delta_1_2[k][j] = inp[k] * layer_2_delta   \n",
    "\n",
    "        for k in range(len(weight_delta_2_3)):\n",
    "            for j in range(len(weight_delta_2_3[k])):\n",
    "                weight_delta_2_3[k][j] = np.sum(layer_2.T[j]) * layer_3_delta\n",
    "\n",
    "        for k in range(len(weight_delta_3_4)):\n",
    "            for j in range(len(weight_delta_3_4[k])):\n",
    "                weight_delta_3_4[k][j] = np.sum(layer_3.T[j]) * layer_4_delta\n",
    "\n",
    "        for k in range(len(weight_delta_4_5)):\n",
    "            weight_delta_4_5[k] = np.sum(layer_4.T[k]) * layer_5_delta\n",
    "\n",
    "\n",
    "        for k in range(len(weight_1_2)):\n",
    "            for j in range(len(weight_1_2)):\n",
    "                weight_1_2[k][j] -= weight_delta_1_2[k][j] * alpha\n",
    "\n",
    "        for k in range(len(weight_2_3)):\n",
    "            for j in range(len(weight_2_3)):\n",
    "                weight_2_3[k][j] -= weight_delta_2_3[k][j] * alpha\n",
    "\n",
    "        for k in range(len(weight_3_4)):\n",
    "            for j in range(len(weight_3_4)):\n",
    "                weight_3_4[k][j] -= weight_delta_3_4[k][j] * alpha\n",
    "\n",
    "        for k in range(len(weight_4_5)):     \n",
    "            weight_4_5[k] -= weight_delta_4_5[k] * alpha\n",
    "            \n",
    "    print(iteration, error, sep=\" --- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a - setosa 0 -0.004040424180493218\n",
      "It is a - setosa 0 0.052764114064569156\n",
      "It is a - setosa 0 0.007786133728707512\n",
      "It is a - setosa 0 0.08875293489072256\n",
      "It is a - setosa 0 -0.009735043311410507\n",
      "It is a - setosa 0 0.11871674826140932\n",
      "It is a - setosa 0 0.06248872126638716\n",
      "It is a - setosa 0 0.04333763490747522\n",
      "It is a - setosa 0 0.08274282684450718\n",
      "It is a - setosa 0 0.040060455399260064\n",
      "It is a - setosa 0 -0.002077665075780999\n",
      "It is a - setosa 0 0.08502107486453525\n",
      "It is a - setosa 0 0.020261030339121078\n",
      "It is a - setosa 0 -0.06026845117551538\n",
      "It is a - setosa 0 -0.14825919128119125\n",
      "It is a - setosa 0 -0.009312623073270743\n",
      "It is a - setosa 0 -0.015638220034801975\n",
      "It is a - setosa 0 0.03251000848645802\n",
      "It is a - setosa 0 0.07976623684234596\n",
      "It is a - setosa 0 0.03687284634327881\n",
      "It is a - setosa 0 0.0943257232895629\n",
      "It is a - setosa 0 0.08316524708263628\n",
      "It is a - setosa 0 -0.1279006158415985\n",
      "It is a - setosa 0 0.225861036187343\n",
      "It is a - setosa 0 0.18578730108669816\n",
      "It is a - setosa 0 0.11589424927116987\n",
      "It is a - setosa 0 0.15002724231543318\n",
      "It is a - setosa 0 0.025500968952048453\n",
      "It is a - setosa 0 0.0016541949504098596\n",
      "It is a - setosa 0 0.1085523599508651\n",
      "It is a - setosa 0 0.11424697908176995\n",
      "It is a - setosa 0 0.1002491044753615\n",
      "It is a - setosa 0 -0.06950127214937041\n",
      "It is a - setosa 0 -0.08842359645339748\n",
      "It is a - setosa 0 0.07661088806620775\n",
      "It is a - setosa 0 -0.03794465516986456\n",
      "It is a - setosa 0 -0.05381856202056845\n",
      "It is a - setosa 0 -0.04223812703685148\n",
      "It is a - setosa 0 0.0394121166980419\n",
      "It is a - setosa 0 0.03929028596596851\n",
      "It is a - setosa 0 0.002968615353903914\n",
      "It is a - setosa 0 0.1401089769303674\n",
      "It is a - setosa 0 0.019928180553215213\n",
      "It is a - setosa 0 0.21338613957692587\n",
      "It is a - setosa 0 0.20777824730644134\n",
      "It is a - setosa 0 0.0933618956730271\n",
      "It is a - setosa 0 0.033911155750375954\n",
      "It is a - setosa 0 0.045422224744259054\n",
      "It is a - setosa 0 0.0019696838657221605\n",
      "It is a - setosa 0 0.019490860905831298\n",
      "It is a - versicolor 1 1.4953195305953368\n",
      "It is a - versicolor 1 1.4889765727632103\n",
      "It is a - versicolor 1 1.612836764424312\n",
      "It is a - versicolor 1 1.3720358501842949\n",
      "It is a - versicolor 1 1.5574858381854089\n",
      "It is a - versicolor 1 1.4831750223094922\n",
      "It is a - versicolor 1 1.5870098704473659\n",
      "It is a - versicolor 1 1.0418054832416779\n",
      "It is a - versicolor 1 1.4705956558375881\n",
      "It is a - versicolor 1 1.3481717153120663\n",
      "It is a - versicolor 1 1.1439034907379249\n",
      "It is a - versicolor 1 1.4279310273934005\n",
      "It is a - versicolor 1 1.251889775548321\n",
      "It is a - versicolor 1 1.560971575286116\n",
      "It is a - versicolor 1 1.1751817245121021\n",
      "It is a - versicolor 1 1.4164373192701092\n",
      "It is a - versicolor 1 1.54083930044008\n",
      "It is a - versicolor 1 1.2448633751433285\n",
      "It is a - versicolor 1 1.5944909513703411\n",
      "It is a - versicolor 1 1.2418149576900017\n",
      "It is a - virginica 1 1.7196308416937587\n",
      "It is a - versicolor 1 1.2990419161732074\n",
      "It is a - versicolor 1 1.695572666507811\n",
      "It is a - versicolor 1 1.4976126780246215\n",
      "It is a - versicolor 1 1.3779241274984315\n",
      "It is a - versicolor 1 1.430226636284015\n",
      "It is a - versicolor 1 1.575970842842061\n",
      "It is a - virginica 1 1.737363037787695\n",
      "It is a - versicolor 1 1.5343918727464683\n",
      "It is a - versicolor 1 1.0571202397129245\n",
      "It is a - versicolor 1 1.222015532629868\n",
      "It is a - versicolor 1 1.1518763578888613\n",
      "It is a - versicolor 1 1.25078675632912\n",
      "It is a - virginica 1 1.7919586940025614\n",
      "It is a - versicolor 1 1.548933998323088\n",
      "It is a - versicolor 1 1.5222324650513617\n",
      "It is a - versicolor 1 1.5537539781592233\n",
      "It is a - versicolor 1 1.4740120269484596\n",
      "It is a - versicolor 1 1.3333834668099627\n",
      "It is a - versicolor 1 1.35255191403947\n",
      "It is a - versicolor 1 1.440614481596322\n",
      "It is a - versicolor 1 1.5176408651396436\n",
      "It is a - versicolor 1 1.2941174664755906\n",
      "It is a - versicolor 1 1.0475001023725792\n",
      "It is a - versicolor 1 1.3961981131012475\n",
      "It is a - versicolor 1 1.3263744272755496\n",
      "It is a - versicolor 1 1.3726668280149177\n",
      "It is a - versicolor 1 1.3860188253814485\n",
      "It is a - versicolor 1 0.9597530237310465\n",
      "It is a - versicolor 1 1.3488200540132826\n",
      "It is a - virginica 2 2.3526174114126395\n",
      "It is a - virginica 2 1.9097046898864285\n",
      "It is a - virginica 2 2.1696740513559707\n",
      "It is a - virginica 2 2.0013772867373962\n",
      "It is a - virginica 2 2.1969198355978996\n",
      "It is a - virginica 2 2.3845585011668238\n",
      "It is a - versicolor 2 1.6909814487265749\n",
      "It is a - virginica 2 2.1960249918407335\n",
      "It is a - virginica 2 2.0913332474091373\n",
      "It is a - virginica 2 2.320554108795914\n",
      "It is a - virginica 2 1.8692138396007927\n",
      "It is a - virginica 2 1.9525980803855152\n",
      "It is a - virginica 2 2.0474611298842706\n",
      "It is a - virginica 2 1.9361976655656594\n",
      "It is a - virginica 2 2.0827148851487856\n",
      "It is a - virginica 2 2.050089970691266\n",
      "It is a - virginica 2 1.94995187870793\n",
      "It is a - virginica 2 2.372714582387033\n",
      "It is a - virginica 2 2.593346116071027\n",
      "It is a - virginica 2 1.7705293596236196\n",
      "It is a - virginica 2 2.1642081942799596\n",
      "It is a - virginica 2 1.8774303682158813\n",
      "It is a - virginica 2 2.3970333977772427\n",
      "It is a - virginica 2 1.785740028363854\n",
      "It is a - virginica 2 2.0894600587566465\n",
      "It is a - virginica 2 2.0700802103428337\n",
      "It is a - virginica 2 1.7464566671588866\n",
      "It is a - virginica 2 1.7646088220296274\n",
      "It is a - virginica 2 2.1167232038691672\n",
      "It is a - virginica 2 1.9492857970056505\n",
      "It is a - virginica 2 2.171092559490482\n",
      "It is a - virginica 2 2.190752792947954\n",
      "It is a - virginica 2 2.1532736365361167\n",
      "It is a - virginica 2 1.7335242464386837\n",
      "It is a - virginica 2 1.8924961581698359\n",
      "It is a - virginica 2 2.2856683071889474\n",
      "It is a - virginica 2 2.1719700423770583\n",
      "It is a - virginica 2 1.944257259577018\n",
      "It is a - virginica 2 1.735067428897075\n",
      "It is a - virginica 2 2.000083070796304\n",
      "It is a - virginica 2 2.1850065508282768\n",
      "It is a - virginica 2 1.9724177099080435\n",
      "It is a - virginica 2 1.9097046898864285\n",
      "It is a - virginica 2 2.235433027369565\n",
      "It is a - virginica 2 2.2356617894244533\n",
      "It is a - virginica 2 2.0238431179375116\n",
      "It is a - virginica 2 1.8753631392496803\n",
      "It is a - virginica 2 1.922286517819666\n",
      "It is a - virginica 2 2.0722894745035045\n",
      "It is a - virginica 2 1.8398810040607465\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(iris_frame[\"sepal length (cm)\"])):\n",
    "        inp = [iris_frame[\"sepal length (cm)\"][i], iris_frame[\"sepal width (cm)\"][i], iris_frame[\"petal length (cm)\"][i], iris_frame[\"petal width (cm)\"][i]]\n",
    "        goal_pred = iris_frame[\"target\"][i]\n",
    "        \n",
    "        layer_2 = np.dot(inp, weight_1_2)\n",
    "        layer_3 = np.dot(layer_2, weight_2_3)\n",
    "        layer_4 = np.dot(layer_3, weight_3_4)\n",
    "        pred = np.sum(np.dot(layer_4, weight_4_5))\n",
    "        if pred <= 0.5:\n",
    "            print(\"It is a - setosa\", goal_pred, pred)\n",
    "        elif pred > 0.5 and pred <= 1.7:\n",
    "            print(\"It is a - versicolor\", goal_pred, pred)\n",
    "        elif pred > 1.7:\n",
    "            print(\"It is a - virginica\", goal_pred, pred)\n",
    "        else:\n",
    "            print(\"I dont know\", goal_pred, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
